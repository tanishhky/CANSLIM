{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: yfinance in /opt/anaconda3/lib/python3.12/site-packages (0.2.41)\n",
      "Requirement already satisfied: alpha_vantage in /opt/anaconda3/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: vaderSentiment in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: quandl in /opt/anaconda3/lib/python3.12/site-packages (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.17.6)\n",
      "Requirement already satisfied: html5lib>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from alpha_vantage) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: inflection>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from quandl) (0.5.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from quandl) (1.16.0)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.12/site-packages (from quandl) (10.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->alpha_vantage) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->alpha_vantage) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->alpha_vantage) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->alpha_vantage) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->alpha_vantage) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas numpy scikit-learn yfinance alpha_vantage requests beautifulsoup4 vaderSentiment quandl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha ZQOPKB408D1QXCA4\n",
    "newsAPI 19e9cf65fc224b5ca79d3932084b982d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Alpha Vantage API key\n",
    "api_key = 'ZQOPKB408D1QXCA4'  # Replace 'YOUR_API_KEY' with your actual Alpha Vantage API key\n",
    "\n",
    "# Function to fetch earnings data from Alpha Vantage API\n",
    "def fetch_earnings_data(ticker):\n",
    "    url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={ticker}&apikey={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if the response contains earnings data\n",
    "    if \"annualEarnings\" in data and \"quarterlyEarnings\" in data:\n",
    "        # Process annual earnings\n",
    "        annual_earnings = pd.DataFrame(data[\"annualEarnings\"])\n",
    "        annual_earnings['Ticker'] = ticker  # Add ticker column for reference\n",
    "        \n",
    "        # Process quarterly earnings\n",
    "        quarterly_earnings = pd.DataFrame(data[\"quarterlyEarnings\"])\n",
    "        quarterly_earnings['Ticker'] = ticker  # Add ticker column for reference\n",
    "\n",
    "        return annual_earnings, quarterly_earnings\n",
    "    else:\n",
    "        print(f\"No earnings data found for {ticker}.\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']  # Replace with desired tickers\n",
    "earnings_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    annual_df, quarterly_df = fetch_earnings_data(ticker)\n",
    "    earnings_data[ticker] = {'Annual': annual_df, 'Quarterly': quarterly_df}\n",
    "\n",
    "    # Save data to CSV files\n",
    "    if not annual_df.empty:\n",
    "        annual_df.to_csv(f'{ticker}_annual_earnings.csv', index=False)\n",
    "    if not quarterly_df.empty:\n",
    "        quarterly_df.to_csv(f'{ticker}_quarterly_earnings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/2708161713.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  earnings_growth = net_income.pct_change().dropna() * 100\n",
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/2708161713.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  earnings_growth = net_income.pct_change().dropna() * 100\n",
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/2708161713.py:18: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  earnings_growth = net_income.pct_change().dropna() * 100\n",
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/2708161713.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  earnings_growth = net_income.pct_change().dropna() * 100\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to download earnings data\n",
    "def download_earnings_data(tickers, start_date, end_date):\n",
    "    data = []\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(start=start_date, end=end_date, interval='1d')\n",
    "        \n",
    "        # Get income statement for net income\n",
    "        income_stmt = stock.income_stmt\n",
    "        \n",
    "        # Extract relevant information from income statement\n",
    "        if income_stmt is not None:\n",
    "            net_income = income_stmt.loc['Net Income']\n",
    "            # Calculate earnings growth as a percentage\n",
    "            earnings_growth = net_income.pct_change().dropna() * 100\n",
    "        else:\n",
    "            net_income = None\n",
    "            earnings_growth = None\n",
    "        \n",
    "        # Append data\n",
    "        data.append({\n",
    "            'Company': ticker,\n",
    "            'Net Income': net_income,\n",
    "            'Earnings Growth (%)': earnings_growth\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "earnings_df = download_earnings_data(tickers, '2015-01-01', '2024-01-01')\n",
    "earnings_df.to_csv('earnings_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# News API key\n",
    "api_key = '19e9cf65fc224b5ca79d3932084b982d'\n",
    "\n",
    "# Function to fetch news data\n",
    "def fetch_news_data(company):\n",
    "    url = f\"https://newsapi.org/v2/everything?q={company}&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    articles = response.json().get('articles', [])\n",
    "    \n",
    "    # Extract relevant data\n",
    "    data = []\n",
    "    for article in articles:\n",
    "        data.append({\n",
    "            'Company': company,\n",
    "            'Date': article['publishedAt'],\n",
    "            'News Headline': article['title'],\n",
    "            'Source': article['source']['name'],\n",
    "            'URL': article['url']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage\n",
    "companies = ['Apple', 'Microsoft', 'Google']\n",
    "news_data = pd.concat([fetch_news_data(company) for company in companies], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "news_data.to_csv('news_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/981840227.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Ticker'] = ticker\n",
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/981840227.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Ticker'] = ticker\n",
      "/var/folders/83/3t5wk1pn2fq83ss49zg61zf40000gn/T/ipykernel_60738/981840227.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Ticker'] = ticker\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_supply_demand_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist = stock.history(start=start_date, end=end_date, interval='1d')\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    data = hist[['Volume', 'Close']]\n",
    "    data['Ticker'] = ticker\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "supply_demand_data = pd.concat([fetch_supply_demand_data(ticker, '2023-01-01', '2024-01-01') for ticker in tickers])\n",
    "\n",
    "# Save to CSV\n",
    "supply_demand_data.to_csv('supply_demand_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Apple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fetch data for each ticker and store in a list\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m tickers:\n\u001b[0;32m---> 29\u001b[0m     df \u001b[38;5;241m=\u001b[39m fetch_institutional_ownership(ticker)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     31\u001b[0m         institutional_data_list\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mfetch_institutional_ownership\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_institutional_ownership\u001b[39m(ticker):\n\u001b[0;32m----> 9\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://financialmodelingprep.com/api/v4/institutional-ownership/name?name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mApple\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&apikey=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     11\u001b[0m     data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Apple' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# FMP API key\n",
    "api_key = 'lhjT6XFmqVkPV78AlKyuNtip6aymeVgT'\n",
    "\n",
    "# Function to fetch institutional ownership data\n",
    "def fetch_institutional_ownership(ticker):\n",
    "    url = f\"https://financialmodelingprep.com/api/v4/institutional-ownership/name?name={Apple}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Check if data is a list (valid response) or not\n",
    "    if isinstance(data, list) and len(data) > 0:\n",
    "        # Convert list of dictionaries to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"No institutional ownership data found for {ticker}.\")\n",
    "        # Return an empty DataFrame if data is not valid\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "institutional_data_list = []\n",
    "\n",
    "# Fetch data for each ticker and store in a list\n",
    "for ticker in tickers:\n",
    "    df = fetch_institutional_ownership(ticker)\n",
    "    if not df.empty:\n",
    "        institutional_data_list.append(df)\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "if institutional_data_list:\n",
    "    institutional_data = pd.concat(institutional_data_list, ignore_index=True)\n",
    "    # Save to CSV\n",
    "    institutional_data.to_csv('institutional_ownership.csv', index=False)\n",
    "else:\n",
    "    print(\"No institutional data to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import pandas as pd\n",
    "\n",
    "# Quandl API key\n",
    "quandl.ApiConfig.api_key = 'WMEE_cWEipLGRy6eaowK'\n",
    "\n",
    "# Function to fetch economic indicators data\n",
    "def fetch_economic_indicators(indicator_code):\n",
    "    data = quandl.get(indicator_code)\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "indicators = ['FRED/GDP', 'FRED/UNRATE', 'FRED/CPIAUCSL']\n",
    "economic_data = pd.concat([fetch_economic_indicators(indicator) for indicator in indicators], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "economic_data.to_csv('market_direction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Sample data for sentiment analysis\n",
    "data = {'Company': ['AAPL', 'MSFT'], 'News Headline': ['Apple releases new iPhone', 'Microsoft acquires new AI startup']}\n",
    "\n",
    "news_df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate sentiment scores\n",
    "news_df['Sentiment Score'] = news_df['News Headline'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "news_df.to_csv('news_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'supply_demand_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m earnings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearnings_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m news_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_sentiment.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m supply_demand_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupply_demand_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m leadership_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarket_leadership.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m ownership_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstitutional_ownership.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'supply_demand_data.csv'"
     ]
    }
   ],
   "source": [
    "# Read all CSV files\n",
    "earnings_df = pd.read_csv('earnings_data.csv')\n",
    "news_df = pd.read_csv('news_sentiment.csv')\n",
    "supply_demand_df = pd.read_csv('supply_demand_data.csv')\n",
    "leadership_df = pd.read_csv('market_leadership.csv')\n",
    "ownership_df = pd.read_csv('institutional_ownership.csv')\n",
    "market_df = pd.read_csv('market_direction.csv')\n",
    "\n",
    "# Merge all DataFrames\n",
    "merged_df = earnings_df.merge(news_df, on='Company').merge(\n",
    "    supply_demand_df, on=['Company', 'Date']\n",
    ").merge(\n",
    "    leadership_df, on=['Company']\n",
    ").merge(\n",
    "    ownership_df, on=['Company', 'Date']\n",
    ").merge(\n",
    "    market_df, on='Date'\n",
    ")\n",
    "\n",
    "# Save merged data\n",
    "merged_df.to_csv('merged_CANSLIM_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'netIncome'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     51\u001b[0m alpha_vantage_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZQOPKB408D1QXCA4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 53\u001b[0m df \u001b[38;5;241m=\u001b[39m collect_canslim_data(tickers, start_date, end_date, alpha_vantage_key)\n\u001b[1;32m     54\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcanslim_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mcollect_canslim_data\u001b[0;34m(tickers, start_date, end_date, alpha_vantage_key)\u001b[0m\n\u001b[1;32m     17\u001b[0m income_stmt \u001b[38;5;241m=\u001b[39m fd\u001b[38;5;241m.\u001b[39mget_income_statement_annual(ticker)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate earnings growth\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m net_income \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(income_stmt\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetIncome\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m earnings_growth \u001b[38;5;241m=\u001b[39m net_income\u001b[38;5;241m.\u001b[39mpct_change()\u001b[38;5;241m.\u001b[39mdropna() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fetch news data (you might want to replace this with a real news API)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4299\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4301\u001b[0m     loc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'netIncome'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def collect_canslim_data(tickers, start_date, end_date, alpha_vantage_key):\n",
    "    fd = FundamentalData(key=alpha_vantage_key)\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    all_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        # Fetch stock data\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist_data = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        # Fetch income statement\n",
    "        income_stmt = fd.get_income_statement_annual(ticker)[0]\n",
    "        \n",
    "        # Calculate earnings growth\n",
    "        net_income = pd.to_numeric(income_stmt.loc['netIncome'], errors='coerce')\n",
    "        earnings_growth = net_income.pct_change().dropna() * 100\n",
    "        \n",
    "        # Fetch news data (you might want to replace this with a real news API)\n",
    "        news_headlines = stock.news\n",
    "        \n",
    "        for date, row in hist_data.iterrows():\n",
    "            data = {\n",
    "                'Date': date,\n",
    "                'Ticker': ticker,\n",
    "                'Close': row['Close'],\n",
    "                'Volume': row['Volume'],\n",
    "                'EPS': stock.info.get('trailingEPS', None),\n",
    "                'Earnings_Growth': earnings_growth.iloc[-1] if not earnings_growth.empty else None,\n",
    "            }\n",
    "            \n",
    "            # Add sentiment analysis\n",
    "            if news_headlines:\n",
    "                headlines = [news['title'] for news in news_headlines if date.date() == pd.to_datetime(news['providerPublishTime'], unit='s').date()]\n",
    "                if headlines:\n",
    "                    sentiment = analyzer.polarity_scores(' '.join(headlines))['compound']\n",
    "                    data['Sentiment'] = sentiment\n",
    "            \n",
    "            all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Example usage\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-01-01'\n",
    "alpha_vantage_key = 'ZQOPKB408D1QXCA4'\n",
    "\n",
    "df = collect_canslim_data(tickers, start_date, end_date, alpha_vantage_key)\n",
    "df.to_csv('canslim_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'canslim_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcanslim_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m results \u001b[38;5;241m=\u001b[39m canslim_analysis(df)\n\u001b[1;32m     55\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcanslim_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'canslim_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def canslim_analysis(df):\n",
    "    results = []\n",
    "    for ticker in df['Ticker'].unique():\n",
    "        stock_data = df[df['Ticker'] == ticker]\n",
    "        \n",
    "        # Current quarterly earnings\n",
    "        current_eps = stock_data['EPS'].iloc[-1]\n",
    "        \n",
    "        # Annual earnings growth\n",
    "        earnings_growth = stock_data['Earnings_Growth'].iloc[-1]\n",
    "        \n",
    "        # New products, management, highs\n",
    "        new_high = stock_data['Close'].iloc[-1] >= stock_data['Close'].max() * 0.95\n",
    "        \n",
    "        # Supply and demand\n",
    "        volume_increase = stock_data['Volume'].pct_change().mean() > 0\n",
    "        \n",
    "        # Leader or laggard\n",
    "        industry_performance = stock_data['Close'].pct_change().mean()\n",
    "        \n",
    "        # Institutional sponsorship\n",
    "        # This would require additional data on institutional ownership\n",
    "        \n",
    "        # Market direction\n",
    "        market_uptrend = stock_data['Close'].pct_change().mean() > 0\n",
    "        \n",
    "        score = sum([\n",
    "            current_eps > 0,\n",
    "            earnings_growth > 25,\n",
    "            new_high,\n",
    "            volume_increase,\n",
    "            industry_performance > 0,\n",
    "            market_uptrend\n",
    "        ])\n",
    "        \n",
    "        results.append({\n",
    "            'Ticker': ticker,\n",
    "            'CANSLIM_Score': score,\n",
    "            'Current_EPS': current_eps,\n",
    "            'Earnings_Growth': earnings_growth,\n",
    "            'New_High': new_high,\n",
    "            'Volume_Increase': volume_increase,\n",
    "            'Industry_Performance': industry_performance,\n",
    "            'Market_Uptrend': market_uptrend\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "df = pd.read_csv('canslim_data.csv')\n",
    "results = canslim_analysis(df)\n",
    "results.to_csv('canslim_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'canslim_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcanslim_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m visualize_canslim_results(results)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'canslim_results.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_canslim_results(results):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Ticker', y='CANSLIM_Score', data=results)\n",
    "    plt.title('CANSLIM Scores by Stock')\n",
    "    plt.ylabel('CANSLIM Score')\n",
    "    plt.savefig('canslim_scores.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(results.set_index('Ticker').iloc[:, 1:], annot=True, cmap='YlGnBu')\n",
    "    plt.title('CANSLIM Factors Heatmap')\n",
    "    plt.savefig('canslim_heatmap.png')\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "results = pd.read_csv('canslim_results.csv')\n",
    "visualize_canslim_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_collection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect_canslim_data\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcanslim_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m canslim_analysis\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m visualize_canslim_results\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_collection'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data_collection import collect_canslim_data\n",
    "from canslim_analysis import canslim_analysis\n",
    "from visualization import visualize_canslim_results\n",
    "\n",
    "def main():\n",
    "    # Set up parameters\n",
    "    tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'FB']  # Add more tickers as needed\n",
    "    start_date = '2023-01-01'\n",
    "    end_date = '2024-01-01'\n",
    "    alpha_vantage_key = 'YOUR_ALPHA_VANTAGE_KEY'\n",
    "\n",
    "    # Collect data\n",
    "    print(\"Collecting data...\")\n",
    "    df = collect_canslim_data(tickers, start_date, end_date, alpha_vantage_key)\n",
    "    df.to_csv('canslim_data.csv', index=False)\n",
    "    print(\"Data collected and saved to canslim_data.csv\")\n",
    "\n",
    "    # Perform CANSLIM analysis\n",
    "    print(\"Performing CANSLIM analysis...\")\n",
    "    results = canslim_analysis(df)\n",
    "    results.to_csv('canslim_results.csv', index=False)\n",
    "    print(\"Analysis complete and saved to canslim_results.csv\")\n",
    "\n",
    "    # Visualize results\n",
    "    print(\"Creating visualizations...\")\n",
    "    visualize_canslim_results(results)\n",
    "    print(\"Visualizations saved as canslim_scores.png and canslim_heatmap.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CANSLIM Analysis for NVDA:\n",
      "C: [] Earnings growth: 581.32%\n",
      "A: [] Average annual growth: 85.32%\n",
      "N: [?] Manual research required for new products or management changes\n",
      "S: [] Trading volume: 413638098\n",
      "L: [?] Manual research required for industry comparison\n",
      "I: [?] Data not available through current API\n",
      "M: [?] Manual analysis of market direction required\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual Alpha Vantage API key\n",
    "API_KEY = 'ZQOPKB408D1QXCA4'\n",
    "\n",
    "def fetch_data(symbol, function, **params):\n",
    "    base_url = 'https://www.alphavantage.co/query'\n",
    "    params.update({\n",
    "        'function': function,\n",
    "        'symbol': symbol,\n",
    "        'apikey': API_KEY\n",
    "    })\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def analyze_current_earnings(symbol):\n",
    "    data = fetch_data(symbol, 'INCOME_STATEMENT', datatype='json')\n",
    "    annual_reports = data.get('annualReports', [])\n",
    "    \n",
    "    if len(annual_reports) < 2:\n",
    "        return False, \"Insufficient data\"\n",
    "    \n",
    "    current_earnings = float(annual_reports[0]['netIncome'])\n",
    "    previous_earnings = float(annual_reports[1]['netIncome'])\n",
    "    \n",
    "    growth_rate = (current_earnings - previous_earnings) / abs(previous_earnings) * 100\n",
    "    \n",
    "    return growth_rate >= 25, f\"Earnings growth: {growth_rate:.2f}%\"\n",
    "\n",
    "def analyze_annual_earnings(symbol):\n",
    "    data = fetch_data(symbol, 'INCOME_STATEMENT', datatype='json')\n",
    "    annual_reports = data.get('annualReports', [])\n",
    "    \n",
    "    if len(annual_reports) < 3:\n",
    "        return False, \"Insufficient data\"\n",
    "    \n",
    "    growth_rates = []\n",
    "    for i in range(len(annual_reports) - 1):\n",
    "        current = float(annual_reports[i]['netIncome'])\n",
    "        previous = float(annual_reports[i+1]['netIncome'])\n",
    "        growth_rate = (current - previous) / abs(previous) * 100\n",
    "        growth_rates.append(growth_rate)\n",
    "    \n",
    "    avg_growth_rate = sum(growth_rates) / len(growth_rates)\n",
    "    \n",
    "    return avg_growth_rate >= 25, f\"Average annual growth: {avg_growth_rate:.2f}%\"\n",
    "\n",
    "def analyze_new_product_or_management():\n",
    "    # This requires manual research and cannot be easily automated\n",
    "    return None, \"Manual research required for new products or management changes\"\n",
    "\n",
    "def analyze_supply_and_demand(symbol):\n",
    "    data = fetch_data(symbol, 'GLOBAL_QUOTE', datatype='json')\n",
    "    volume = int(data['Global Quote']['06. volume'])\n",
    "    \n",
    "    # You may need to adjust this threshold based on the specific stock and market\n",
    "    high_volume_threshold = 100000\n",
    "    \n",
    "    return volume > high_volume_threshold, f\"Trading volume: {volume}\"\n",
    "\n",
    "def analyze_leader_or_laggard(symbol):\n",
    "    # This requires comparison with industry peers and cannot be easily automated\n",
    "    return None, \"Manual research required for industry comparison\"\n",
    "\n",
    "def analyze_institutional_sponsorship(symbol):\n",
    "    # This data is not readily available through Alpha Vantage\n",
    "    return None, \"Data not available through current API\"\n",
    "\n",
    "def analyze_market_direction():\n",
    "    # This requires analysis of broader market indices\n",
    "    return None, \"Manual analysis of market direction required\"\n",
    "\n",
    "def analyze_stock(symbol):\n",
    "    results = {\n",
    "        'C': analyze_current_earnings(symbol),\n",
    "        'A': analyze_annual_earnings(symbol),\n",
    "        'N': analyze_new_product_or_management(),\n",
    "        'S': analyze_supply_and_demand(symbol),\n",
    "        'L': analyze_leader_or_laggard(symbol),\n",
    "        'I': analyze_institutional_sponsorship(symbol),\n",
    "        'M': analyze_market_direction()\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    symbol = input(\"Enter the stock symbol to analyze: \")\n",
    "    results = analyze_stock(symbol)\n",
    "    \n",
    "    print(f\"\\nCANSLIM Analysis for {symbol}:\")\n",
    "    for factor, (passed, message) in results.items():\n",
    "        status = \"\" if passed else \"\" if passed is not None else \"?\"\n",
    "        print(f\"{factor}: [{status}] {message}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
